# Rebecca

# Doodler instructions

You have to make an ssh tunnel to copy and paste the address that Doodler spits out:

1. ssh to andes or polaris
2. Do the instructions on the Github to install dash doolder. When installing Dash Doodler navigate to the `dash_doodler` directory with `cd dash_doodler`. Don’t worry about conda version errors. It will take a while.
3. activate your `dashdoodler` environment you created when installing Doodler
4. Run `python [doodler.py](http://doodler.py)` after navigating to the directory with `cd dash_doodler`
5. You have to make an ssh tunnel to copy and paste the address that Doodler spits out. Note the address: it should be `[http://127.0.0.1:8050/](http://127.0.0.1:8050/)`  The server is 127.0.0.1 and the port is 8050. 

![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled.png)

1. Open another Terminal. Do `ssh` like you normally would but add flags `-NfL` (note capitals). The general syntax for ssh tunneling is:

`ssh -NfL [port]:[server]:[port] [your net id]@[linux machine address]`

so replicate the following but with your username

![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%201.png)

1. Copy and paste or type the http address into your web browser of choice. It should pop us as Doodler!!

## Google Earth Engine scripts

***NEW*** 

1. Change the `folder` variable to the Google Drive folder you’d like to send files to
2. Add the HYBAS_ID of your next watershed and run the script. It will take a bit. 
3. Use the Layers tab to click through different dates. Pick your favorite and adjust the `imageDate` variable accordingly
    
    ![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%202.png)
    
4. Once you confirm that the `RGB` layer that automatically plots in the map viewer looks like the scene you want, submit the watershed task and confirm that the popup window is the correct name, folder etc. 
    
    ![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%203.png)
    
    ![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%204.png)
    

```jsx
// Set the date for the imagery
// Pick the "best" date in ImageCollection -> features
var imageDate = ee.Date('2020-5-21')

var HYBAS_ID=3100133910

var shed = ee.FeatureCollection("WWF/HydroSHEDS/v1/Basins/hybas_10")
.filter(ee.Filter.eq('HYBAS_ID', HYBAS_ID))

print(shed.first())
// print(shed.toDictionary().values())
// to do: grab hybas id as client side string for export

Map.addLayer(shed, false)

var centroid = shed.geometry().centroid()
var geometry = centroid.buffer({'distance': 20000})
Map.addLayer(geometry, false)
// Map.setCenter(
//   shed.geometry().centroid().coordinates().get(0).getInfo(),
//   shed.geometry().centroid().coordinates().get(1).getInfo(),
//   11)
// I am proud of this one lol
Map.centerObject(centroid, 11) 

function maskS2clouds(image) {
  var qa = image.select('QA60');

  // Bits 10 and 11 are clouds and cirrus, respectively.
  var cloudBitMask = 1 << 10;
  var cirrusBitMask = 1 << 11;

  // Both flags should be set to zero, indicating clear conditions.
  var mask = qa.bitwiseAnd(cloudBitMask).eq(0)
      .and(qa.bitwiseAnd(cirrusBitMask).eq(0))
      ;

  return image.updateMask(mask)
  .divide(10000)
  .copyProperties(image, ['system:time_start']);
}
function clp(img) {
  return img.clip(shed)
}////
function mosaicByDate(imcol){
  // imcol: An image collection
  // returns: An image collection
  var imlist = imcol.toList(imcol.size())

  var unique_dates = imlist.map(function(im){
    return ee.Image(im).date().format("YYYY-MM-dd")
  }).distinct()

  var mosaic_imlist = unique_dates.map(function(d){
    d = ee.Date(d)

    var im = imcol
      .filterDate(d, d.advance(1, "day"))
      .mosaic()

    return im.set(
        "system:time_start", d.millis(), 
        "system:id", d.format("YYYY-MM-dd"))
  })

  return ee.ImageCollection(mosaic_imlist)
}
////
function addNDWI(image) {
  var ndwi = image.normalizedDifference(['B3', 'B8A']).rename('NDWI');
  return image.addBands(ndwi);
};
function addNDVI(image) {
  var ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI');
  return image.addBands(ndvi);
};
////
var dataset = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')
                  .filter(ee.Filter.calendarRange(2019,2019,'year'))
                  .filter(ee.Filter.calendarRange(5,8,'month'))
                  // Pre-filter to get less cloudy granules.
                  .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))
                  .filterBounds(shed.geometry().centroid())
                  // .filter(ee.Filter.contains('.geo', shed))
                  .map(clp)
                  .map(maskS2clouds);

var dataset = mosaicByDate(dataset).map(addNDWI).map(addNDVI)

print(dataset)

var ndwiParams = {min: -1, max: 1, palette: ['yellow', 'blue']};
var ndviViz = {palette: 'brown, blanchedalmond, #8FBC8F, #006400',};

var s2Params = {min: -1, max: 1, palette: ['black', 'white']};

var varParams = {min: -1, max: 4, palette: ['black', 'white']};

var rgbViz = {
  min: 0.0,
  max: 0.1,
  bands: ['B4', 'B3', 'B2'],
};
//*

Map.addLayer(dataset.select('NDVI'), s2Params, 'NDVI', false);
Map.addLayer(dataset.select('NDWI'), s2Params, 'NDWI', false);

Map.addLayer(dataset.filterDate(imageDate), rgbViz, 'RBG')

var ndwi_st = dataset.select('NDWI')
.reduce(ee.Reducer.kurtosis())
Map.addLayer(ndwi_st, varParams, 'NDWI_stdev', false);

var imageRGB = dataset.filterDate(imageDate).first().visualize(rgbViz)
var imageNDVI = dataset.select('NDVI').filterDate(imageDate).first().visualize(s2Params)
var imageNDWI = dataset.select('NDWI').filterDate(imageDate).first().visualize(s2Params)
var imageNDWI_stdev = ndwi_st.visualize(s2Params)

Export.image.toDrive({
  image: imageRGB,
// Don't forget to change these!!!!!
  description: ee.String(HYBAS_ID.toString()).cat('_rgb').getInfo(),
  folder: "random_state_2",
// Change me!!!
	region: geometry,
  scale: 10,
  fileDimensions: 512, // you can change this
  skipEmptyTiles: true,
  crs: 'EPSG:5936', //polar
  //maxPixels: 1e13
  maxPixels: 163164208
})

Export.image.toDrive({
  image: imageNDVI,
// Don't forget to change these!!!!!
  description: ee.String(HYBAS_ID.toString()).cat('_ndvi').getInfo(),
  folder: HYBAS_ID.toString(),
// Change me!!!
	region: geometry,
  scale: 10,
  fileDimensions: 1024, // you can change this
  skipEmptyTiles: true,
  crs: 'EPSG:5936', //polar
  //maxPixels: 1e13
  maxPixels: 163164208
})

Export.image.toDrive({
  image: imageNDWI,
// Don't forget to change these!!!!!
  description: ee.String(HYBAS_ID.toString()).cat('_ndwi').getInfo(),
  folder: HYBAS_ID.toString(),
// Change me!!!
	region: geometry,
  scale: 10,
  fileDimensions: 1024, // you can change this
  skipEmptyTiles: true,
  crs: 'EPSG:5936', //polar
  //maxPixels: 1e13
  maxPixels: 163164208
})

Export.image.toDrive({
  image: dataset.filterDate(imageDate).first().select('B4', 'B3', 'B2','B8', 'B8A'),
// Don't forget to change these!!!!!
  description: ee.String(HYBAS_ID.toString()).cat('_multiband').getInfo(),
  folder: HYBAS_ID.toString(),
// Change me!!!
	region: geometry,
  scale: 10,
  fileDimensions: 1024, // you can change this
  skipEmptyTiles: true,
  crs: 'EPSG:5936', //polar
  //maxPixels: 1e13
  maxPixels: 163164208
})
Export.table.toDrive({
  collection: shed,
  // Me too!!!!!!
  description: HYBAS_ID.toString(),
  folder: 'random_state_2',
  fileNamePrefix: HYBAS_ID.toString(),
  // Me too!!!!!
  fileFormat: 'SHP'
});

var args = {
  dimensions: '1200x600',
  region: geometry,
  framesPerSecond: 3,
    // crs: 'EPSG:5936', //polar
  min: 0.0,
  max: 0.1,
  bands: ['B4', 'B3', 'B2'],
};
var thumb = ui.Thumbnail({
  image: dataset,
  params: args,
  });

print(thumb)

var listOfImages = dataset.toList(dataset.size()); // 29 images

print(ee.Image(listOfImages.get(0)).date().format('yyyy-MM-dd'))
// client side loop
for(var i = 0; i < 30; i++){
  var image = ee.Image(listOfImages.get(i));
  Map.addLayer(image, rgbViz, 
  ee.Image(image).date().format('yyyy-MM-dd').getInfo(), false
  // i.toString()
  )
}

// var slider = ui.Slider();
// slider.onSlide(function(value) {
//   var int_value = value * (Map.layers().length() - 1) >> 0;
//   Map.layers().get(int_value).setOpacity(1);
//   for (var i = int_value + 1; i < Map.layers().length(); i++) {
//     Map.layers().get(i).setOpacity(0);
// }
// });
// print(slider);

// make a slider
// var slider = ui.Slider({min: 0, 
//                         max: Map.layers().length() - 1, 
//                         value: 0, 
//                         step: 1});
// print(slider);

// slider.onSlide(function(value) {
  
//   // set opacity all layers 0
//   for (var i = 0; i < Map.layers().length(); i++) {
//     Map.layers().get(i).setOpacity(0);
//   }
  
//   // set opacity slided layer to 1
//   Map.layers().get(value).setOpacity(1);
// });
```

To pull single watershed AOI by HYBAS_ID (HYBAS10_Exporter):

```jsx
var HYBAS_ID=8100086980 // change this

var shed = ee.FeatureCollection("WWF/HydroSHEDS/v1/Basins/hybas_10")
.filter(ee.Filter.eq('HYBAS_ID', HYBAS_ID))

print(shed.first())

Export.table.toDrive({
  collection: shed,
  description: '8100086980',
  folder: 'hybas10_sheds',
  fileNamePrefix: '8100086980',
  fileFormat: 'SHP'
});
```

To download 512x512 Planet imagery (RGB_tile_exporter):

```jsx
///Change the list of images depending on how many images you need to upload
var planet = ee.ImageCollection.fromImages([image, image2, image3, image4])

var mosaics = planet.mosaic()
// Mask out water
var waterMask = ee.ImageCollection('MODIS/006/MOD44W')
              .filter(ee.Filter.date('2015-01-01', '2015-01-02'))
              .select('water_mask')
              .first();

var imageMasked = image.updateMask(waterMask.select('water_mask').lt(1))

// Make RBG
var imageRGB = imageMasked.visualize({
  "bands":["b3","b2","b1"],
  min:405.79,
  max:4499.71,
  gamma:2.331
}
)

// View image
Map.addLayer(imageRGB, {}, 'image')

// Export tiled 

Export.image.toDrive({
  image: imageRGB,
  description: 'HYBASID',
  folder: 'HYBASID',
  // Don't forget to draw your stupid box around the watershed. 
	region: geometry,
  scale: 3,
  fileDimensions: 512,
  skipEmptyTiles: true,
	crs:'EPSG:32607', // change this
  //maxPixels: 1e13
  maxPixels: 163164208
})
```

## RC notes

text

Don’t use Discovery for interactive, just running on head node so it’s kind of a weak node, you can use it on andes or polaris and it’ll actually be faster, they have individually beefier CPUs, less network latency. Other option is locally and then DartFS mounted locally. 

Training on Dartmouth. Is Gym set up for parallelization? Don’t run Discovery interactive session on. 

GPU node reservation and then ssh into it directly or request and interactive node engagement. 

[https://services.dartmouth.edu/TDClient/1806/Portal/KB/ArticleDet?ID=132460](https://services.dartmouth.edu/TDClient/1806/Portal/KB/ArticleDet?ID=132460) 

Doodler just needs TensorFlow 

typescript keystrokes 

email zoe whenever!!! 

## Steps

1. Select a watershed and grab its HYBAS_ID in `\\dartfs\rc\lab\V\VecchioJ\arctic_image_segmentation\watershed_catalog` in the file called `random_sheds_for_doodling_notes.xlsx`. Copy the `HYBAS_ID` of a watershed is that is not italicized (check to make sure a folder with its name does not already exist on the lab directory). Once you have it coped italicize the row to mark off it’s been done. 
2. run the GEE HYBAS10_Exporter script by pasting the hybas ID as the second argument in the ee.Filter function (so that it is a number (blue text), not a string)
3. After double-checking with the print statement that everything looks good (sub_area = up_area) then go over to the orange “Tasks” tab and hit run on the unsubmitted task
4. make sure the ID is the file name, the drive folder is something useful like hybas10_sheds/<<HYBAS_ID>>, and file format is shapefile and hit Run. This will take a few seconds but you can check the Task Manager. 
5. Navigate to the subfolder in drive and download all of the files (shold be 5 or 6 of them) by selecting all. this will give you a zip drive. I recommend deleting the files once they’re downloaded so you don’t get it mixed up with other files. 
6. unzip this zip drive into the `arctic_image_segmentation/watershed_catalog/HYBAS10_shapefiles` directory on the VecchioJ lab folder. (1 min)
7. Now go to Planet Explorer ([https://www.planet.com/explorer/](https://www.planet.com/explorer/)) and find the dashed square icon on the left that is “draw or upload a geometry”
8. click upload and navigate to the shapefile directory and drop all the files into the spot.
9. Adjust the search filters so that you are not limited by date, only searching planetscope 3m data, use SuperDove, NIR, start with 0% clouds, and ground control and standard image quality. 
    
    ![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%205.png)
    
10. Find a scene that looks good and click the blue “order scenes” button and order the data for download. make the order name the HYBAS_ID
11. only download “corrected for surface reflectance” rectified assets and select the **8 band** (not 4 band) assets.  On next page keep clip and harmonize selected. hopefully if you have 100% coverage there shouldn’t be nodata so don’t deselect anything.
12. hit order and this will take at least 25 minutes if not more, so go back to Step 1 and work up another order while you wait. When it is done download the zipped files and unzip them to a folder called `planet_Export` (protip: this is really just for archive, we will save the exact same data as geotiffs)
13. Back in GEE, go to Assets, New, Image Upload. Navigate to where you downloaded the Planet imagery. In this subfolder sort by file size and only select the SR_Harmonized_clip files (not udm2) ~~and select all of them. this way GEE automatically mosaics the files so that they are a single Image asset (99% sure, need to confirm, potential source of error). This will also take ~10 mins?~~ Not sure why but this stopped working, it was giving an error that the area of overlap was too big for the images if we load them in all at once. So now you have to upload the assets individually. I recommend adding them to a folder with the watershed ID as the name. 
14. Once you finish uploading and processing go to cloud assets, click on the file and then hit “import” at the top right for each image. they will be brought in as `image`, `image2`, `image3` etc. 
15. run the RGB_tile_exporter script, ensuring your Drive folder name is RGB_export/HYBAS ID and the file is the name of the HYBAS ID, that you are in a GeoTIFF, and that your file dimensions are 512. **This is an annoying thing, but you have to draw a box around the watershed in order to export it. I don’t know why and I hate it.**  Go over to the symbols on the left and select the rectangle and draw a rectangle around the watershed. This will automatically import a `var geometry: Polygon`, as seen in the screenshot below:
    
    ![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%206.png)
    
16. You will also need to adjust the coordinate reference system (crs) to get nice-looking photos, so follows these steps:
    1. Look at this webpage to see a map of UTM Zones. These are zones for certain coordinate reference systems [http://www.baspsoftware.org/airphotose_files/hs1100.htm](http://www.baspsoftware.org/airphotose_files/hs1100.htm) Find the zone your location is in 
    2. Google “EPSG UTM Zone [zone]” and use the zone you determined. the results will be something like EPSG:32607 
        
        ![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%207.png)
        
    3. grab that five digit number and plop it into the Google Earth Engine script next to `crs`
        
        ![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%208.png)
        
    4. (This sucks also and I will figure out how to get around this with code)
17. After the script finishes running download and unzip the file into HYBAS10_imagery directory and make a new folder with the HYBAS ID as the name. Then inside there make a folder called `geotiffs` and drop al lthe GeoTIFF “chips” in here. 
18. Copy the `make_jpgs.py` script from the main project directory and drop it in the directory with the HYBAS10_imagery/<<your ID here>> (NOT within `geotiffs`)
19. Load up Terminal and ssh into Polaris or Andes and navigate to the directory with the HYBAS10_imagery/<<your ID here>> 
20. Run the make_jpgs.py script from the terminal with `python make_jpgs.py` when you have navigated to the directory with the HYBAS10_imagery/<<your ID here>> **Note!!!! on your first time you should install the package `osgeo` into your environment (`dashdooodler` or `base`, whatever) with `conda install -c conda-forge gdal`. This will take some time, just be patient.** 
21. Do Doodler!!!!
    1. 
22. Move all the labels, results, overlays etc. back to the lab directory for storage. Delete the .jpgs in the `asset` folder of Dash Doodler when you’re done. 
23. Repeat! 

# Segmentation Gym instructions

1. Use the `utils/gen_images_and_labels.py` script in Doodler (in your Doodler environment!) to generate the labels and images folders that you can point segmentation gym to. It helps if you put all your results that you want to use in one directory. A dumb thing is that you have to click into the directory when the prompt comes up (rather than selecting the folder). 
2. Log into Discovery

```jsx
ssh [id]@discovery7.dartmouth.edu
```

1. Start an [interactive session](https://services.dartmouth.edu/TDClient/1806/Portal/KB/ArticleDet?ID=132460) on Discovery. when you type `k80:4`  that means you are using 4 GPUs at once 😎 you do training in super-speed!! But if you aren’t doing any operations it could time out because those resources are sometimes high in demand. 

```jsx
srun -p gpuq --gres=gpu:k80:4 --pty /bin/bash
```

1. Making sure you installed Segmentation Gym according to the GitHub, activate your `gym` environment

```jsx
conda activate gym
```

1. Follow the [Segmentation Gym wiki](https://github.com/Doodleverse/segmentation_gym/wiki) and have fun!

![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%209.png)

![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%2010.png)

![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%2011.png)

![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%2012.png)

![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%2013.png)

after a while of thinking the model training probably takes 10 mins

![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%2014.png)

![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%2015.png)

![Untitled](Rebecca%20088c274042c04e808282ed5439784a08/Untitled%2016.png)

/dartfs/rc/lab/V/VecchioJ/arctic_image_segmentation/joanmarie_dev/seg_gym_dev/shed_subset/random_state_0/toPredict
/dartfs/rc/lab/V/VecchioJ/arctic_image_segmentation/joanmarie_dev/seg_gym_dev/shed_subset/weights/resunet_inspired_by_l8_in_gym_fullmodel.h5
Using GPU
Using multiple GPUs
Version:  2.6.2
Eager mode:  True
Version:  2.6.2
Eager mode:  True
GPU name:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:
Num GPUs Available:  4
[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_
WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING
Your GPUs may run slowly with dtype policy mixed_float16 because they do not have compute capability of at least 7.0. Your GPUs:
Tesla K80, compute capability 3.7 (x4)
See [https://developer.nvidia.com/cuda-gpus](https://developer.nvidia.com/cuda-gpus) for a list of GPUs and their compute capabilities.
If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once
[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_vice:GPU:3', device_type='GPU')]
Number of distributed devices: 4
.....................................
Creating and compiling model 0...
Number of samples: 370
.....................................
Using model for prediction on images ...
0%|                                                                                                                                                                                                                                                       /dartfs-hpc/rc/home/1/f005dv1/.conda/envs/gym/lib/python3.9/site-packages/doodleverse_utils/prediction_imports.py:557: UserWarning: No contour levels were found within the data range.
cs = plt.contour(est_label, [-99,0,99], colors='r')
0%|7                                                                                                                                                                                                                                                      /dartfs-hpc/rc/home/1/f005dv1/.conda/envs/gym/lib/python3.9/site-packages/doodleverse_utils/prediction_imports.py:205: RuntimeWarning: invalid value encountered in true_divide
return (mx-mn)*(dat-m)/(M-m)+mn
/dartfs/rc/lab/V/VecchioJ/arctic_image_segmentation/joanmarie_dev/seg_gym_dev/shed_subset/random_state_0/toPredict/3100010930_rgb-0000000512-0000002048.jpg failed. Check config file, and check the path provided contains valid imagery
2%|#####6

############| 370/370 [16:27<00:00,  2.67s/it]
Exception ignored in: <function Pool.**del** at 0x2b88e0d69160>
Traceback (most recent call last):
File "/dartfs-hpc/rc/home/1/f005dv1/.conda/envs/gym/lib/python3.9/multiprocessing/pool.py", line 268, in **del**
File "/dartfs-hpc/rc/home/1/f005dv1/.conda/envs/gym/lib/python3.9/multiprocessing/queues.py", line 371, in put
AttributeError: 'NoneType' object has no attribute 'dumps'